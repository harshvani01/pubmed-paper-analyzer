# PubMed Paper Analyzer
A Python-based tool to analyze PubMed papers by extracting summaries and results tables. It includes a REST API to trigger processing.

# üöÄ Features
  üìÑ Summarization: Extracts and summarizes key information from research papers.
  üìä Results Table Extraction: Identifies and extracts primary results tables from PDFs.
  üî• Parallel Processing: Uses multi-threading for efficient batch processing.
  üåê REST API: Simple API to trigger processing and retrieve results.
  
# üìÇ Project Structure
pubmed-paper-analyzer/
‚îÇ‚îÄ‚îÄ data/                 # Contains raw PDFs and extracted data
‚îÇ   ‚îú‚îÄ‚îÄ papers/           # Input PDFs
‚îÇ   ‚îú‚îÄ‚îÄ summaries/        # Generated summaries
‚îÇ   ‚îú‚îÄ‚îÄ tables/           # Extracted results tables
‚îÇ‚îÄ‚îÄ logs/                 # Log files
‚îÇ‚îÄ‚îÄ src/                  # Source code
‚îÇ   ‚îú‚îÄ‚îÄ summarizer.py     # Extracts and summarizes paper content
‚îÇ   ‚îú‚îÄ‚îÄ table_extractor.py# Extracts primary results tables
‚îÇ   ‚îú‚îÄ‚îÄ api.py            # REST API to trigger processing
‚îÇ‚îÄ‚îÄ main.py               # Orchestrates the entire workflow
‚îÇ‚îÄ‚îÄ requirements.txt      # Python dependencies
‚îÇ‚îÄ‚îÄ README.md             # Project documentation

# üîß Setup
  1Ô∏è‚É£ Install Dependencies
    Create a virtual environment and install required packages:
  
    python -m venv pubmed_analyzer_env
    source pubmed_analyzer_env/bin/activate  # (Linux/macOS)
    pubmed_analyzer_env\Scripts\activate     # (Windows)

    pip install -r requirements.txt
    
# üìä Usage
  Run the analysis manually:
    -> add the desired paper URLs in the input_urls.txt and then the below command.
    python main.py
  Run the REST API:
    uvicorn src.api:app --host 0.0.0.0 --port 8000
  API Endpoints:
  Method	 Endpoint 	Description
  GET	        /	      API health check
  POST	   /analyze	  Triggers main.py processing
  GET      /summary/{pubmed_id}   get the summary of a paper based on pubmed id.
  GET      /table/{pubmed_id}     get result table of the paper based on the pubmed id.
  
# üìù Logs & Outputs
  Summaries: data/summaries/
  Tables: data/tables/
  Logs: logs/
  
# üõ†Ô∏è Troubleshooting
  1Ô∏è‚É£ No summaries/tables generated?
  
  Check logs/ for errors.
  Ensure data/papers/ has valid PDFs.
  2Ô∏è‚É£ API not responding?

  Ensure uvicorn is running (http://127.0.0.1:8000).
  
# üìú License
  This project is for educational purposes. Feel free to modify and extend!

# Sample
  You can find the Sample/ directory which contains the sample papers and their summary and tables extracted.

# PubMed Paper Analyzer - Key Highlights
PDF Summarization:
  Extracts text from research papers using PyMuPDF.
  Splits text into chunks and summarizes them using Hugging Face‚Äôs BART-Large model.
  Stores summaries in structured text files inside the data/summaries/ directory.
Results Table Extraction:
  Identifies and extracts the primary results table from each PDF.
  Converts tables into structured CSV format for easy analysis.
Logging & Robust Error Handling:
  Comprehensive logging system tracks processing steps and errors.
  Handles edge cases such as empty PDFs, missing text, and malformed tables.
Parallel Processing for Efficiency:
  Uses ThreadPoolExecutor to process multiple papers in parallel.
  Improves performance when handling large batches of PDFs.
RESTful API for Automation:
  Simple Flask-based API to trigger the analysis process.
  Provides endpoints to retrieve summaries and tables for specific papers.
Well-Structured Codebase:
  Organized into src/ for main logic and data/ for processed outputs.
  Uses configurable directory paths to ensure proper file organization.
  
This implementation efficiently extracts and summarizes research findings while maintaining scalability, automation, and structured data storage. üöÄ


